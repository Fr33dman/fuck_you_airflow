{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Mining с sberpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека __`sberpm`__ предназначена для анализа и исследования процессов, построения их в виде графов и решения смежных задач классификации и кластеризации с использованием алгоритмов машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление\n",
    "\n",
    "[DataHolder](#DataHolder)\n",
    "\n",
    "[Синтетические ID процесса](#Синтетические-ID-процесса)\n",
    "\n",
    "[----------  Традиционный-Process-Mining  ----------](#----------Традиционный-Process-Mining----------)\n",
    "\n",
    "I. [Майнеры и визуализация графов](#I.-Майнеры-и-визуализация-графов)\n",
    " 1. [SimpleMiner](#1.-SimpleMiner)\n",
    " 2. [CausalMiner](#2.-CausalMiner)\n",
    " 3. [HeuMiner](#3.-HeuMiner)\n",
    " 4. [AlphaMiner](#4.-AlphaMiner)\n",
    " 5. [AlphaPlusMiner](#5.-AlphaPlusMiner)\n",
    " 6. [InductiveMiner](#6.-InductiveMiner)\n",
    "\n",
    "II. [Метрики](#II.-Метрики)\n",
    "- [Метрики + графы](#Метрики-+-графы)\n",
    "\n",
    "III. [Conformance Checking](#III.-Conformance-Checking)\n",
    "\n",
    " IV. [BPMN](#IV.-BPMN)\n",
    "\n",
    "V. [Визуализация](#V.-Визуализация)\n",
    "\n",
    "\n",
    "\n",
    "[---------- Машинное-обучение ----------](#----------Машинное-обучение----------)\n",
    "\n",
    "[Проверка наличия моделей](#Проверка-наличия-моделей)\n",
    "\n",
    "I. [Кластеризация этапов](#I.-Кластеризация-этапов)\n",
    "\n",
    "II. [Автоматический поиск неэффективностей](#II.-Автоматический-поиск-неэффективностей)\n",
    "\n",
    "III. [Поиск аномалий](#III.-Поиск-аномалий)\n",
    "\n",
    "IV. [Факторный анализ](#IV.-Факторный-анализ)\n",
    "\n",
    "V. [Рекомендательная система](#V.-Рекомендательная-система)\n",
    "\n",
    "VI. [Анализ текстов](#VI.-Анализ-текстов)\n",
    "\n",
    "VII. [Сентиментный анализ](#VII.-Сентиментный-анализ)\n",
    "\n",
    "VIII. [Поиск счастливого пути](#VIII.-Поиск-счастливого-пути)\n",
    "\n",
    "IX. [Предсказание структуры графа](#IX.-Предсказание-структуры-графа)\n",
    "\n",
    "X. [Имитационное моделирование и what-if анализ](#X.-Имитационное-моделирование-и-what-if-анализ)\n",
    "\n",
    "XI. [Decision Mining](#XI.-Decision-Mining)\n",
    "\n",
    "XII. [Хронометраж](#XII.-Хронометраж)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataHolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataHolder` – это базовый класс для хранения данных. Практически все алгоритмы библиотеки работают с ним (принимают на вход).\n",
    "\n",
    "Для создания класса `DataHolder` необходимо сперва указать путь к файлу или передать DataFrame конструктору, а затем указать __id_column__ и __activity_column__. Однако, для большинства алгоритмов Process Mining, представленных в библиотеке, этих столбцов недостаточно – необходимы хотя бы одна колонка времени (__start_timestamp_column__ и/или __end_timestamp_column__) и колонка пользователей (__user_column__). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры DataHolder\n",
    "- **data (str or pd.DataFrame)** – путь к файлу данных (.csv, .xls(x), .txt) или pd.DataFrame\n",
    "- **id_column (str)** – столбец id\n",
    "- **activity_column (str)** – столбец активностей\n",
    "- __<font color='red'>*</font>start_timestamp_column (str)__ – время начала активностей\n",
    "- __<font color='red'>*</font>end_timestamp_column (str)__ – время окончания активностей\n",
    "- __user_column (str)__ – столбец с именами/id пользователей\n",
    "- __text_column (str)__ – столбец с текстовыми данными\n",
    "- __duration_column (str)__ – столбец с длительностями активностей (если не задается, то расчитывается как время_активности_2 - время_активности_1, причем если есть только один столбец со временем, то для последней активности в цепочке ставится NaN)\n",
    "- __duration_unit (str)__ – размерность (единица измерения) значений в столбце duration_column, если он задан\n",
    "\n",
    "- __sep (str, default=',')__ – разделительный знак (используется только при чтении данных из файла)\n",
    "- __encoding (str)__ – кодировка (используется только при чтении данных из файла)\n",
    "- __nrows (int)__ – количество строк для чтения (используется только при чтении данных из файла)\n",
    "\n",
    "- __preprocess (bool, default=True)__ – предобработка данных (сортировка, удаление None-значений, преобразование типов)\n",
    "- __time_format (str)__ – формат временных колонок (обязательно задавать для правильного распознавания даты и ускорения работы). Правила написания: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
    "- __time_errors: (str, default='raise')__ – действие при ошибке конвертации\n",
    "- __dayfirst: (bool, default=None)__ – True, если день стоит в начале строки\n",
    "- __yearfirst: (bool, default=None)__ – True, если год стоит в начале строки\n",
    "- __n_jobs (int, default=1)__ – максимальное количество потоков, доступное для некоторых вычислений\n",
    "\n",
    "\n",
    "__<font color='red'>*</font>__ Для большинства алгоритмов нужно задать хотя бы один из временных столбцов. Если нет информации о типе столбца (время начала или конца), следует задать его как __start_timestamp_column__. Для верного распознавания формата также необходимо указать __time_format__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуемые данные должны представлять собой журнал событий (лог-файл), в котором хранится информация о последовательности (цепочке) событий (активностей) в бизнес-процессах. Пример журнала событий: $W = \\{(a,b,c,d), (a,c,b,d), (a,e,d)\\}$, где события $a$, $b$, $c$, $d$ и $e$ сортируются по времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание DataHolder \n",
    "### – с помощью DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm import DataHolder\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id_column': [1, 1, 2, 2, 3, 3],\n",
    "                   'activity_column': ['st1', 'st2', 'st1', 'st3', 'st1','st2'],\n",
    "                   'start_timestamp_column': ['10.05.2020', '10.09.2020', '10.03.2020', '10.04.2020', '10.05.2020', '10.05.2020']})\n",
    "\n",
    "data_holder = DataHolder(data=df, \n",
    "                         id_column='id_column', \n",
    "                         activity_column='activity_column', \n",
    "                         start_timestamp_column='start_timestamp_column', \n",
    "                         time_format='%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### – с помощью указания пути файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = 'example.xlsx'\n",
    "data_holder = DataHolder(data=path, \n",
    "                         id_column='id', \n",
    "                         activity_column='stages', \n",
    "                         start_timestamp_column='dt', \n",
    "                         user_column='users', \n",
    "                         text_column=\"some_text\",\n",
    "                         time_format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данные имеют какой-нибудь разделитель, например '|' как в csv, то после задания колонок, нужно задать параметр __sep='|'__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Атрибуты DataHolder\n",
    "В `DataHolder` названия столбцов хранятся в соответствующих переменных (т.е. нет необходимости запоминать названия колонок):\n",
    "- id_column\n",
    "- activity_column\n",
    "- start_timestamp_column\n",
    "- end_timestamp_column\n",
    "- user_column\n",
    "- text_column\n",
    "- duration_column\n",
    "\n",
    "Кроме того, в `DataHolder` хранятся исходные и сгруппированные данные в виде DataFrame, к которым можно обратиться следующим образом:\n",
    "- data\n",
    "- grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы DataHolder\n",
    "- __check_or_calc_duration__ – рассчитывает длительность каждой активности (в секундах), если это необходимо \n",
    "- __get_grouped_data__ – выводит сгруппированные данные по id и указанным колонкам (например, по activity_column и start_timestamp_column)\n",
    "- __get_unique_activities__ – выводит список уникальных активностей\n",
    "- __get_columns__ – выводит список с названиями колонок \n",
    "- __get_text__ – выводит колонку с текстом, если такая есть\n",
    "- __get_timestamp_col__ – выводит временную колонку; если их имеется 2, то выводит start_time_column\n",
    "- __is_interval__ – возвращает True, если это \"интервальный лог\" (у которого имеются обе временные колонки: начала и конца активности)\n",
    "- __top_traces_dh__ – возвращает data_holder с данными для n самых частых цепочек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holder.check_or_calc_duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holder.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holder.get_grouped_data(data_holder.activity_column, data_holder.start_timestamp_column).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_3 = data_holder.top_traces_dh(3)  # данные только для топ 3 цепочек\n",
    "dfg = dh_3.get_grouped_data(dh_3.activity_column)\n",
    "dfg.value_counts(dh_3.activity_column)  # проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Имея данные о бизнес-процессе с цепочками статусов и временем начала каждого из них, можно загрузить их в `DataHolder` и построить граф, максимально описывающий этот бизнес-процесс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Синтетические ID процесса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pro_n_check__ нумерует экземпляры процессов в зависимости от заданных условий. Создает столбец 'pro_n'.\n",
    "\n",
    "Параметры:\n",
    "- __data__ - объект хранения данных в формате DataFrame.\n",
    "- __proc_columns__ - список столбцов с этапами процесса.\n",
    "- __identifier_cols__ - список столбцов с идентификаторами процессов (если один из идентификаторов, указанных в списке, изменяется, считается, что запущен новый процесс).\n",
    "- __start_proc__ - список строковых значений, указывающих на начало процесса.\n",
    "- __end_proc__ - список строковых значений, указывающих на завершение процесса.\n",
    "- __sort_params__ - список столбцов для сортировки (должен использоваться в случае смешанных данных).\n",
    "\n",
    "Методы:\n",
    "- __get_pro_n()__ - при запуске добавляется столбец 'pro_n' к исходному датасету. (Возвращает DataFrame)\n",
    "- __get_result()__ - получить готовый результат. Работает, если метод 'get_pro_n' был запущен ранее. (Возвращает DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.pro_n_check import Pro_n_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('example.xlsx')\n",
    "pro_n = Pro_n_check(data = df,\n",
    "                    proc_columns= ['stages'],\n",
    "                    identifier_cols = ['id'],\n",
    "                    start_proc = ['Stage_0'],\n",
    "                    end_proc = ['Stage_2'],\n",
    "                    sort_params = ['id','dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_n.get_pro_n()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------Традиционный Process Mining----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Майнеры и визуализация графов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения и отрисовки графа процесса в библиотеке реализовано несколько алгоритмов. Все они хранятся в модуле __`sberpm.miners`__ и имеют один метод:\n",
    "- __apply__ – строит граф, который сохраняется в поле graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SimpleMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimpleMiner` отрисовывает все ребра, найденные в логе (без какой-либо фильтрации).\n",
    "\n",
    "В терминах Process Mining:\n",
    "> Если хотя бы в одной цепочке активностей из лога за некоторой активностью $X$ непосредственно следует активность $Y$ (цепочка вида $...XY...$), то пишут $X>Y$ ($Y$ follows $X$, _follows_ relation).\n",
    "\n",
    "SimpleMiner рисует ребра между такими парами активностей $X$ и $Y$, если выполняется $X>Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import SimpleMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта SimpleMiner. В конструктор подается DataHolder и параметры алгоритма \n",
    "# (у данного майнера параметров нет)\n",
    "simple_miner = SimpleMiner(data_holder)\n",
    "\n",
    "# Запуск алгоритма построения графа\n",
    "simple_miner.apply()\n",
    "\n",
    "# Сохранение графа\n",
    "graph = simple_miner.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Визуализация графа\n",
    "Для визуализации графа следует использовать `GraphvizPainter` из модуля __`sberpm.visual`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sberpm.visual import GraphvizPainter\n",
    "import os\n",
    "os.environ['PATH'] += os.pathsep + \"C:/Program Files (x86)/Graphviz2.38/bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Класс `GraphvizPainter` имеет методы:\n",
    "- __apply__ – принимает на вход граф, полученный с помощью майнера, и производит расчет для его отрисовки \n",
    "- __write_graph__ – сохраняет граф в требуемом формате (pdf, svg, gv, png)\n",
    "- __show__ – выводит граф в notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта GraphvizPainter\n",
    "painter = GraphvizPainter()\n",
    "\n",
    "# Расчет графа по результатам работы SimpleMiner\n",
    "painter.apply(graph)\n",
    "\n",
    "# Можно сохранить граф на жесткий диск в формате png, svg, pdf или gv\n",
    "painter.write_graph('SimpleMiner.png', format='png')\n",
    "\n",
    "# Можно вывыести граф в notebook\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `Graph` из модуля __`sberpm.visual`__ имеет методы:\n",
    "- __get_nodes__ – получить все узлы\n",
    "- __get_edges__ – получить все ребра\n",
    "- __add_node_metric__ – добавить метрику, связанную с узлами графа\n",
    "- __add_edge_metric__ – добавить метрику, связанную с ребрами графа\n",
    "- __clear_node_metrics__ – удалить все метрики с нод (узлов)\n",
    "- __clear_edge_metrics__ – удалить все метрики с ребер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CausalMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CausalMiner` основан на фильтрации ребер.\n",
    "> Производные типы связей от $X>Y$:\n",
    "- прямые связи ($X \\to Y$, _causal_ relation) – это связи, где $Х>Y$ и не $Y>X$\n",
    "- параллельные связи($X\\parallel Y $, _parallel_ relation) – это связи, где $Х>Y$ и $Y>X$\n",
    "- независимые связи ($X\\#Y$, independent) – это связи, где не $X>Y$ и не $Y>X$\n",
    "\n",
    "CausalMiner рисует ребра между такими парами активностей $X$ и $Y$, если выполняется $X\\to Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import CausalMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "causal_miner = CausalMiner(data_holder)\n",
    "causal_miner.apply()\n",
    "graph = causal_miner.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. HeuMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HeuMiner` – это эврестический майнер, который удаляет наиболее редкие связи в зависимости от задаваемого порога (threshold). \n",
    "\n",
    "Параметр **threshold** принимает значения **от 0 до 1**. Чем он больше, тем меньше ребер на графе (оставшиеся ребра считаются более важными).\n",
    "\n",
    "Источник: https://www.researchgate.net/publication/229124308_Process_Mining_with_the_Heuristics_Miner-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import HeuMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "heu_miner = HeuMiner(data_holder, threshold=0.8)\n",
    "heu_miner.apply()\n",
    "graph = heu_miner.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. AlphaMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AlphaMiner` рисует граф в виде сетей Петри с учетом прямых, параллельных и независимых связей между активностями. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import AlphaMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "alpha_miner = AlphaMiner(data_holder)\n",
    "alpha_miner.apply()\n",
    "graph = alpha_miner.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. AlphaPlusMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AlphaPlusMiner` – имплементация Alpha+ майнера, который также рисует граф в виде сетей Петри с учетом связей, но в отличие от AlphaMiner может работать с одноцикловыми (one-loop) цепочками вида activity_1$\\to$activity_1 (самоцикл)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.miners import AlphaPlusMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Майнер\n",
    "alpha_miner_plus = AlphaPlusMiner(data_holder)\n",
    "alpha_miner_plus.apply()\n",
    "graph = alpha_miner_plus.graph\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. InductiveMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`InductiveMiner` создаёт дерево процесса. Лисья дерева - реальные активности процесса, остальные вершины - операторы. Есть 4 типа операторов: \n",
    "- ПОСЛЕДОВАТЕЛЬНЫЙ (`->`), \n",
    "- ИСКЛЮЧАЮЩЕЕ ИЛИ (`X`), \n",
    "- ПАРАЛЛЕЛЬНЫЙ (`||`), \n",
    "- ЦИКЛ (`*`).\n",
    "\n",
    "Есть дополнительный 'оператор', который говорит о том, что было невозможно найти ни один из 4 операторов, представленных выше:\n",
    "- СМЕШЕННАЯ МОДЕЛЬ ('`?`')\n",
    "\n",
    "*Замечание*: некоторые из листьев дерева могут быть *скрытыми активностями*, отображаемыми чёрными прямоугольниками. Они не являются реальными активностями и используются только для сохранения правильной структуры дерева. \n",
    "\n",
    "Например, из лога, состоящего из двух цепочек процесса $W = \\{(a, b, c), (a, c)\\}$, можно получить следующее дерево процеса:        \n",
    "`->(a, X(b, скрытая_активность), c)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если во время очередной итерации алгоритм не может найти разрез графа (=подобрать один из 4 операторов), возможно добавить следубщее поведение: если существует активность А, при удалении которой удаётся подобрать оператор, алгоритм возвращает следующее дерево:            \n",
    "`||(X(активность_А, скрытая_активность), граф_без_активности_А)` - то есть активность А считается параллельной остальному графу.\n",
    "\n",
    "\n",
    "Это поведение может быть включено или выключено параметром **parallel_activity** в классе `InductiveMiner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import InductiveMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miner\n",
    "inductive_miner = InductiveMiner(data_holder)\n",
    "inductive_miner.apply()\n",
    "graph = inductive_miner.graph\n",
    "\n",
    "# Visualization\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## II. Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент в модуле __`sberpm.metrics`__ есть 5 основных типов метрик:\n",
    "1. `ActivityMetric` – метрики по активностям (группировка по activity_column)\n",
    "2. `TransitionMetric` – метрики по переходам (группировка по уникальным переходам)\n",
    "3. `IdMetric`– метрики по id (группировка по id_column)\n",
    "4. `TraceMetric` – метрики по цепочкам активностей (группировка по уникальным цепочкам)\n",
    "5. `UserMetric` – метрики по пользователям (группировка по user_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.metrics import ActivityMetric, TransitionMetric, IdMetric, TraceMetric, UserMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры:\n",
    "- __data_holder__ – объект типа DataHolder, для которого надо рассчитать метрики\n",
    "- __time_unit__ – единица времени, по умолчанию расчет временных метрик происходит в часах\n",
    "- __round__ – количество цифр после запятой (только для метрик, значения которых могут быть с плавающей точкой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие методы для всех классов:\n",
    "- __apply__ – расчет всех характеристик\n",
    "- __calc_metrics(...)__ – расчет указанных метрик (соответствуют методам/названиям колонок в DataFrame из apply)\n",
    "- __calculate_time_metrics__ – расчет временных характеристик\n",
    "\n",
    "- __total_duration__ – расчет суммарного времени работы\n",
    "- __min_duration__ – расчет минимального времени работы\n",
    "- __max_duration__ – расчет максимального времени работы\n",
    "- __mean_duration__ – расчет среднего времени работы\n",
    "- __median_duration__ – расчет медианного времени работы\n",
    "- __std_duration__ – расчет стандартного отклонения времени работы\n",
    "- __var_duration__ – расчет дисперсии времени работы\n",
    "\n",
    "Дополнительные методы:\n",
    "- ActivityMetric\n",
    "    - __count__ - сколько раз активность встречается в логе\n",
    "    - __unique_ids__ - уникальные id для каждой активности\n",
    "    - __unique_ids_num__ - количество уникальных id для каждой активности\n",
    "    - __aver_count_in_trace__ - среднее количество раз встречаемости активности в цепочке\n",
    "    - __loop_percent__ - процент зацикленности\n",
    "    - __throughput__ - частота - количество выполненных активностей за единицу времени\n",
    "    - __unique_users__ - уникальные пользователи, работавшие с данной активностью\n",
    "    - __unique_users_num__ - количество уникальных пользователей, работающих над данной активностью\n",
    "    - __success_rate(...)__ - доля id, имеющих данную активность, которая выполнилась успешно (закончились успешными активностями)\n",
    "    - __failure_rate(...)__ - доля id, имеющих данную активность, которая выполнилась неуспешно (закончились неуспешными активностями)\n",
    "    \n",
    "    \n",
    "- IdMetric\n",
    "    - __trace__ - цепочка (список активностей)\n",
    "    - __trace_length__ - длина цепочки (кол-во активностей в цепочке)\n",
    "    - __unique_activities__ - уникальные активности в цепочке\n",
    "    - __unique_activities_num__ - количество уникальных активностей в цепочке\n",
    "    - __loop_percent__ - процент зацикленности\n",
    "    - __unique_users__ - уникальные пользователи, работающие с этим ID\n",
    "    - __unique_users_num__ - кол-во уникальных пользователей, работавших с данным ID\n",
    "\n",
    "- TraceMetric\n",
    "    - __count__ - сколько раз данная цепочка встречается в логе\n",
    "    - __ids__ - уникальные id с данной цепочкой\n",
    "    - __trace_length__ - длина цепочки (кол-во активностей в цепочке)\n",
    "    - __unique_activities__ - уникальные активности в цепочке\n",
    "    - __unique_activities_num__ - количество уникальных активностей в цепочке активностей\n",
    "    - __unique_users__ - уникальные пользователи, работающие над цепочкой активностей\n",
    "    - __unique_users_num__ - количество уникальных пользователей, работающих над цепочкой активностей\n",
    "\n",
    " \n",
    "- TransitionMetric\n",
    "    - __count__ - сколько раз данный переход встречается в логе\n",
    "    - __unique_ids__ - уникальные id  для каждого перехода\n",
    "    - __unique_ids_num__ - количество уникальных id для каждого перехода\n",
    "    - __aver_count_in_trace__ - среднее количество раз встречаемости объекта в цепочке\n",
    "    - __loop_percent__ - процент зацикленности\n",
    "    - __throughput__ - частота - количество выполненных переходов за единицу времени\n",
    "    - __unique_users__ - уникальные пользователи, работающие над объектом\n",
    "    - __unique_users_num__ - кол-во уникальных пользователей, работающих над объектом\n",
    "    - __success_rate(...)__ - доля id, имеющих текущий переход, которые выполнились успешно (закончились успешными активностями)\n",
    "    - __failure_rate(...)__ - доля id, имеющих текущий переход, которые выполнились неуспешно (закончились неуспешными активностями)\n",
    "    \n",
    "    \n",
    "- UserMetric\n",
    "    - __count__ - сколько раз данный пользователь встречается в логе\n",
    "    - __unique_activities__ - уникальные активности, с которыми работал пользователь\n",
    "    - __unique_activities_num__ - количество уникальных активностей, с которыми работал пользователь\n",
    "    - __unique_ids__ - уникальные id с данным пользователем\n",
    "    - __unique_ids_num__ - количество уникальных id с данным пользователем\n",
    "    - __throughput__ - число раз выполнения объекта за единицу времени\n",
    "    - __workload__ - доля активности лога, выполненных данным пользователем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ActivityMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта ActivityMetric\n",
    "activity_metric = ActivityMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "activity_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. TransitionMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создание объекта TransitionMetric\n",
    "transition_metric = TransitionMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "transition_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. IdMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта IdMetric\n",
    "id_metric = IdMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "id_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. TraceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Создание объекта TraceMetric\n",
    "trace_metric = TraceMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "trace_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. UserMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Создание объекта UserMetric\n",
    "user_metric = UserMetric(data_holder, time_unit='d')\n",
    "\n",
    "# Расчет всех метрик\n",
    "user_metric.apply().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Метрики + графы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке реализована возможность представить ряд метрик на графе. Сделать это можно в классе `Graph` с помощью методов:\n",
    "- __add_node_metric__ – добавить метрику, связанную с узлами графа\n",
    "- __add_edge_metric__ – добавить метрику, связанную с ребрами графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Расчет метрик\n",
    "nodes_count_metric = activity_metric.count().to_dict()\n",
    "edges_count_metric = transition_metric.count().to_dict()\n",
    "mean_time_node_metric = activity_metric.mean_duration().fillna(0).to_dict()\n",
    "\n",
    "# Получение графа из майнера\n",
    "graph = causal_miner.graph\n",
    "\n",
    "# Добавление метрик на граф\n",
    "graph.add_node_metric('count', nodes_count_metric)\n",
    "graph.add_edge_metric('count', edges_count_metric)\n",
    "graph.add_node_metric('mean_time', mean_time_node_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта GraphvizPainter\n",
    "painter = GraphvizPainter()\n",
    "\n",
    "# Отрисовать граф и связать цвет узлов и ребер с нужными метриками\n",
    "painter.apply(graph, node_style_metric='count', edge_style_metric='count')\n",
    "# или painter.apply(graph, node_style_metric='mean_time', edge_style_metric='count')\n",
    "\n",
    "# Сохранение графа\n",
    "painter.write_graph(\"metric_graph.png\", format = 'png')\n",
    "\n",
    "# Отображение в jupyter-notebook\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы удалить метрики с графа, следует воспользоваться следующими методами:\n",
    "- __clear_node_metrics__ – удалить все метрики с нод (узлов)\n",
    "- __clear_edge_metrics__ – удалить все метрики с ребер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.clear_node_metrics()\n",
    "graph.clear_edge_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Conformance Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TokenReplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TokenReplay` позволяет рассчитать *fitness*, который показывает, насколько хорошо граф описывает бизнесс-процесс (1 – хорошо, 0 – плохо). Fitness вычисляется отдельно для каждой цепочки (id) при ее проигрывании по сети Петри по следующей формуле:\n",
    "$$ Fitness = \\frac{1}{2}\\Big(1-\\frac{missed}{consumed}\\Big) + \\frac{1}{2}\\Big(1-\\frac{remaining}{produced}\\Big) $$\n",
    "- produced tokens – появились в результате перехода\n",
    "- consumed tokens – удалились в результате перехода\n",
    "- remaining tokens – остались в конце проигрывания\n",
    "- missing tokens – не было, но они необходимы для проигрывания, поэтому их вставляют\n",
    "\n",
    "Библиотека выдает следующие метрики:\n",
    "- значения 4 величин и fitness каждой цепочки\n",
    "- усредненный fitness по всем цепочкам (__mean_fitness__)\n",
    "- fitness по всему логу – в формулу подставляются суммарные значения 4 величин по всем цепочкам в логе (__average_fitness__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.conformance_checking import TokenReplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_replay = TokenReplay(data_holder, alpha_miner.graph)\n",
    "token_replay.apply()\n",
    "token_replay.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean:', token_replay.mean_fitness)\n",
    "print('average:', token_replay.average_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в библиотеке доступен более общий класс ConformanceChecking, сдержащий TokenReplay и рад других метрик:\n",
    "- precision\n",
    "- generalization\n",
    "- simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.conformance_checking import ConformanceChecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ConformanceChecking(data_holder, alpha_miner.graph)\n",
    "cc.get_conformance_checking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.get_fitness_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. BPMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сохранения графа в формате BPMN (Business Process Model and Notation) можно воспользоваться `BpmnExporter` из модуля __`sberpm.bpmn`__. Он имеет следующие методы:\n",
    "- __apply_petri__ – построить BPMN для сети Петри\n",
    "- __get_string_representation__ – получить BPMN-нотацию графа\n",
    "- __write__ – записать граф в BPMN формате\n",
    "\n",
    "На данный момент сохранять можно только графы, полученные из Alpha Miner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.bpmn import BpmnExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bpmn_exporter = BpmnExporter()\n",
    "bpmn_exporter.apply(alpha_miner.graph)\n",
    "bpmn_exporter.get_string_representation()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpmn_exporter.write('exported.bpmn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для загрузки BPMN-файла есть класс `BpmnImporter` со следующими методами:\n",
    "- __load_bpmn_from_xml__ – загрузить граф, представленный в виде BPMN\n",
    "- __get_pydotplus_graph__ – получить граф в формате pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sberpm.bpmn import BpmnImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bpmn_importer = BpmnImporter()\n",
    "bpmn_importer.load_bpmn_from_xml('exported.bpmn')\n",
    "pydot_graph = bpmn_importer.get_pydotplus_graph()\n",
    "pydot_graph.write('imported_bpmn.svg', prog='dot', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `ChartPainter` из модуля __`sberpm.visual`__ предназначен для создания основных типов графиков. В основе визуализации лежит библиотека __`plotly`__, благодаря чему все диаграммы являются интерактивными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.visual import ChartPainter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры:\n",
    "- __data__ – данные, которые необходимо визуализировать (DataFrame, DataHolder или объекта класса метрик)\n",
    "- __template__ – стиль графиков, по умолчанию _plotly_\n",
    "- __palette__ – цветовая палитра графиков, по умолчанию _sequential.Sunset_r_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый метод `ChartPainter` позволяет отрисовать график определенного типа:\n",
    "- __hist__ – гистограмма\n",
    "- __bar__ – столбчатая диаграмма\n",
    "- __box__ – ящичковая диаграмма\n",
    "- __scatter__ – диаграмма рассеяния\n",
    "- __line__ – линейный график\n",
    "- __pie__ – круговая диаграмма\n",
    "- __sunburst__ – диаграмма солнечные лучи\n",
    "- __heatmap__ – 2D гистограмма\n",
    "- __timeline__ – диаграмма Ганта\n",
    "- __pareto__ – диаграмма Парето\n",
    "\n",
    "Основные параметры методов (для более подробной информации см. документацию):\n",
    "- __x__, __y__ – названия столбцов для отрисовки по осям X и Y соответственно\n",
    "- __sort__ – название столбца для сортировки значений\n",
    "- __n__ – количество строк для визуализации\n",
    "- __color__ – название столбца для задания цвета элементам графика\n",
    "- __subplots__ – кортеж вида (rows, cols, ncols), где rows и cols – это названия столбцов для отрисовки нескольких графиков по рядам и столбцам соответственно, а ncols – это количество столбцов\n",
    "- __text__ – название столбца с текстовой информацией (или ее вид) для отображения на графике\n",
    "- __orientation__ – ориентация графика\n",
    "- __opacity__ – прозрачность элементов графика\n",
    "- __edge__ – границы элементов графика\n",
    "- __title__ – название графика\n",
    "\n",
    "Каждый метод прост в использовании, но при этом обладает достаточно широким функционалом, который позволяет построить графики для любых задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(id_metric)\n",
    "painter.hist(x='total_duration', edge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Столбчатая диаграмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(user_metric)\n",
    "painter.bar(x=data_holder.user_column, y='total_duration', text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Диаграмма рассеяния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(id_metric)\n",
    "painter.scatter(x='mean_duration', y='median_duration', color='unique_users_num', size='trace_length', \n",
    "                edge=True, opacity=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Круговая диаграмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(user_metric)\n",
    "painter.pie(labels='count', n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограмма распрелделения активностей по диапазонам времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По всем активностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = ChartPainter(data_holder)\n",
    "painter.hist_activity_of_dur(top= False, use_median=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По топ активностям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter.hist_activity_of_dur(top= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### По одной активности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter.hist_activity_of_dur(by_activity='Stage_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ----------Машинное обучение----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка наличия моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sberpm.models\n",
    "Данный модуль используется для проверки __необходимых__ моделей библиотеки, без которых __не будут работать__ некоторые модули представленные ниже.\n",
    "\n",
    "Модели можно скачать с репозитория на __BitBucket__.\n",
    "\n",
    "В данный момент в библиотеке используются следующие модели:\n",
    "- __Navec__\n",
    "- __PM__\n",
    "- __Bert__\n",
    "\n",
    "\n",
    "В модуле хранятся следующая функция:\n",
    "- __check_contained_models()__ - с помощью этой функции можно проверить имеющиеся модели.\n",
    "- __get_models_path()__ - c помощью этой функции можно узнать путь к файлу библиотеки, и конкретно к папке, в которой должны храниться соотвествующие модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sberpm.models as check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.check_contained_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.get_models_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Кластеризация этапов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный модуль служит для кластеризации этапов процесса, для нахождения близких или идентичных этапов процессов. \n",
    "\n",
    "Рассматриваются только уникальные названия этапов процессов. Для кластеризации используется лемматизация алгоритмами библиотеки __Natasha__ всех слов с последующим отображением этапа процесса с помощью нейронной сети Navec в 300-мерное пространство, на основании которого можно рассчитать попарные расстояния Word Mover's Distance между этапами процессов, полученные данные образуют матрицу расстояний. На основании этой матрицы производится кластеризация методом __DBSCAN__. Полученные кластеры образуют близкие этапы процесса.\n",
    "\n",
    "После кластеризации выбираются кластеры с неотрицательными номерами. Каждый такой кластер указывает на схожие этапы процесса. -1 кластер указывает на этапы, на которые нет похожих.\n",
    "\n",
    "Параметры передаваемые в класс __StagesClustering__:\n",
    "- __data (SberPM DataHolder или pandas DataFrame)__ - класс с хранящимися данными.\n",
    "- __stages_col (str)__ - столбец данных, содержащий текстовые названия этапов процесса.\n",
    "- __generalizing_ability (float = default 0.5)__ - Коэффициент обобщающей способности (указывается в пределах [0;1]). Чем ниже будет коэффициент, тем больше будет кластеров.\n",
    "- __type_model_w2v (bool = default True)__ - выбор модели:\n",
    "    - True- общая модель\n",
    "    - Fasle - модель специализированная для сбербанка\n",
    "\n",
    "Методы класса __StagesClustering__:\n",
    "- __apply()__ - запустит процесс анализа.\n",
    "- __get_clustered_result()__ - вернёт pandas DataFrame с указанием кластера каждого этапа.\n",
    "- __get_result_data()__ - вернёт исходный pandas DataFrame с добавленной колонкой 'clusters'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.stages_clustering import StagesClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage_clust = StagesClustering(data=data_holder, stages_col='some_text')\n",
    "Stage_clust.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Stage_clust.get_clustered_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage_clust.get_result_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  II. Автоматический поиск неэффективностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль автоматического поиска неэффективностей __`sberpm.autoinsights`__ позволяет в автоматическом режиме выявить __слабые места и уязвимости процесса__ и наглядно продемонстрировать их на графе процесса. При анализе классом `AutoInsights` учитываются такие факторы, как:\n",
    "1. Длительность этапа\n",
    "2. Рост длительности этапа\n",
    "3. Нерегулярность (редкость) этапа\n",
    "4. Зацикленность\n",
    "5. Этап имеет bottleneck c низкой вариативностью\n",
    "6. Этап имеет bottleneck c высокой вариативностью\n",
    "7. Этап имеет большую длительность из-за частых повторений инцидентов\n",
    "8. Этап имеет большую длительность из-за разовых инцидентов\n",
    "9. Этап приводит к росту времени процесса и/или прочих этапов\n",
    "10. Этап проходит с ошибками, что приводит к замедлению процесса\n",
    "11. Этап проходит с критическими ошибками системы, что приводит к неуспеху процесса\n",
    "12. Этап проходит со структурными ошибками, что приводят к неуспеху процесса\n",
    "13. Сторнирование на данном этапе приводит к неуспеху замедлению процесса\n",
    "14. Сторнирование на данном этапе приводит к неуспеху процесса\n",
    "15. Уровень аномальности\n",
    "16. Сумма финансовых эффектов\n",
    "\n",
    "Общим итогом вычислений являются следующие два параметра:\n",
    "- __Уровень аномальности - *[0, 1]*__\n",
    "\n",
    "    Для каждого объекта (активность и ребро) считается его уровень аномальности - метрика со значениями от 0 до 1 включительно. Чем больше уровень аномальности, тем больше инсайтов может дать объект.\n",
    "- __Сумма финансовых эффектов - *[0, +inf)*__\n",
    "    \n",
    "    Сумма финансовых эффектов представляет собой суммы финэффектов по каждой метрике в таблице, получаемой через *get_clustered_result*. Финэффект рассчитывается для каждой активности на основе стоимости 'секунды работы человека' *sec_cost*. Также, в зависимости от метрики, на финэффект влияют продолжительности этапов, циклы и другие проблемы активности или активностей, от которой зависит текушая активность. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoInsights имеет следующие параметры:\n",
    "- **data_holder (SberPM DataHolder)** – экземпляр класса DataHolder с хранящимися данными\n",
    "- **success_activity (string = default None)** - этап представляющий успешный процесс\n",
    "- **clust_eps (float = default 0.1)** - обообщенный гиперпараметр для DBSCAN и IsolationForest\n",
    "- **sec_cost (float = default 0.01)** - стоимость минуты человеческой работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoInsights имеет следующие методы:\n",
    "- **apply()** – выполняет расчет неэффективностей во входном логе.\n",
    "- **get_result()** – возвращает таблицу инсайтов виде отнормированных значений для каждого фактора.\n",
    "- **get_clustered_result()** – возвращает таблицу кластеризованных метрик инсайтов для активностей.\n",
    "- **get_boolean_clustered_result()** – возвращает таблицу кластеризованных метрик инсайтов для активностей, со значениями True/False.\n",
    "- **get_description()** - возвращает текстовое описание ненулевых финэффектов по таблице кластеризованных метрик инсайтов.\n",
    "- **get_transition_ai()** – возвращает таблицу уровней аномальности для переходов между парами активностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.autoinsights import AutoInsights\n",
    "\n",
    "auto_i = AutoInsights(data_holder)\n",
    "auto_i.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица метрик инсайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_i.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица кластеризованных метрик инсайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_i.get_clustered_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица кластеризованных инсайтов с метриками True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_i.get_boolean_clustered_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текстовое описание ненулевых финэффектов по таблице кластеризованных метрик инсайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto_i.get_description())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица уровней аномальности для переходов с этапа на этап "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_i.get_transition_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Визуализация инсайтов на графе\n",
    "\n",
    "Для визуализации следует воспользоваться методом **apply_insights** классов `sberpm.visual.GraphvizPainter` или `sberpm.visual.MlPainter`. Нужно подать :\n",
    "- **граф** для отрисовки (на нём может быть меньше нод/рёбер, чем в таблицах автоинсайтов), \n",
    "- **объект `AutoInsights`**, у которого был вызван метод apply\n",
    "- параметры отрисовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.miners import heu_miner\n",
    "\n",
    "graph = heu_miner(data_holder, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "painter = GraphvizPainter()\n",
    "painter.apply_insights(graph, auto_i)\n",
    "painter.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графе нет чисто красных рёбер, так как HeuMiner вернул граф, на котором присутствуют не все рёбра, то есть \"инсайтных\" рёбер на графе просто нет. Можно получить граф со всеми возможными рёбрами при помощи SimpleMiner, но он будет слишком большой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## III. Поиск аномалий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выявление аномалий__ (также __обнаружение выбросов__) — это распознавание во время интеллектуального анализа данных редких данных, событий или наблюдений, которые вызывают подозрения ввиду существенного отличия от большей части данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска аномалий (выбросов) в данных в библиотеке есть модуль __`sberpm.ml.anomaly_detection`__, в котором есть классы `OutlierCBLOF`, `OutlierForest`, `OutlierLOF`, `OutlierOCSVM`, `OutlierCustom`, `OutlierEnsemble`. В каждом классе реализован свой алгоритм __выявления аномалий без учителя__, который обнаруживает аномалии в непомеченных наборах данных при предположении, что большая часть набора данных нормальна, путем поиска представителей, которые меньше подходят к остальному набору данных. \n",
    "\n",
    "`OutlierEnsemble` это композиция алгоритмов обнаружения аномалий, итоговой ответ которой представляет собой голосование (объект считается выбросом, если большинство алгоритмов определило его как выброс) следующих алгоритмов: [KNN](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn), [ABOD](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod), [HBOS](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos), [Isolation Forest](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.anomaly_detection import OutlierCBLOF, OutlierForest, OutlierLOF, \\\n",
    "                                        OutlierOCSVM, OutlierCustom, OutlierEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве параметра объект принимает на вход DataHolder, по которому рассчитывает базовые статистики, такие как среднее время, длина цепочки активностей, число уникальных пользователей (если они есть) и т. д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierForest(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Каждый класс имеет следующие методы:\n",
    "- __add_feature__ – добавление признака, по которому требуется найти аномалии \n",
    "- __add_groupby_feature__ – добавление признака для поиска аномалий, рассчитанного по сгруппированным данным \n",
    "- __apply__ – запуск алгоритма\n",
    "- __get_outlier_ids__ – вывод id аномальных процессов\n",
    "- __print_result__ – вывод статистики по аномалиям\n",
    "- __show_permutation_importance__ – иллюстрация permutation importance признаков, по которым отличаются выбросы (работает везде кроме `OutlierEnsemble`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Добавление признака с именем max_time, вычисляемого путем применения функции max к колонке \n",
    "# data_holder.duration_column в сгруппированных по id данных (масимальное время активности в процессе)\n",
    "outlier_detector.add_groupby_feature('max_time', data_holder.duration_column, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле реализовано 5 техник выявления аномалий:\n",
    "1. __Isolation Forest (IF)__\n",
    "2. __One-Class Support Vector Machines (OCSVM)__\n",
    "3. __Local Outlier Factor (LOF)__\n",
    "4. __Cluster-Based Local Outlier Factor (CBLOF)__\n",
    "5. `OutlierEnsemble` в котором есть __KNN__, __HBOS__, __ABOD__, __Isolation Forest__\n",
    "\n",
    "Также можно использовать любой другой алгоритм поиска аномалий (например, из библиотеки __pyod__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest\n",
    "\n",
    "> В основе техники __изолирующего леса__ лежит идея о том, что аномальные наблюдения легче отделить от остальных (нормальных) объектов датасета. Алгоритм строит ансамбль изолирующих бинарных деревьев решений, в каждом узле которого выбор признака и порога разбиения производится случайным образом. Дерево строится до тех пор, пока в листе не останется только один объект или объекты с одинаковыми значениями. Интуитивно понятно, что __аномальные__ точки – это те, что имеют меньшую длину пути в дереве, которая определяется как число ребер, которые объект проходит от корневого узла до листа. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierForest(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### One-Class Support Vector Machines\n",
    "\n",
    "> Основная идея классического __метода опорных векторов (SVM)__ заключается в разделении объектов, относящихся к разным классам, гиперплоскостью так, чтобы максимизировать расстояние между ними. Алгоритм __OCSVM__, как следует из названия, обучается на данных, принадлежащих одному классу – классу нормальных объектов. Он определяет границы этих объектов и классифицирует все остальные точки, лежащие по другую сторону от разделяющей поверхности, как __аномальные__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierOCSVM(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Local Outlier Factor\n",
    "\n",
    "> __Локальный уровень выброса (LOF)__ основывается на концепции локальной плотности объекта, где локальность задается его $k$ ближайшими соседями, расстояния до которых используются в качестве оценки плотности. Путем сравнения локальной плотности объекта с локальной плотностью его соседей, можно выделить области с аналогичной плотностью и точки, которые имеют существенно меньшую плотность, чем ее соседи. Эти точки считаются __выбросами__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierLOF(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cluster-Based Local Outlier Factor\n",
    "\n",
    "> В отличие от стандартного LOF, основанном на метрическом подходе к выявлению локальных выбросов, __CBLOF__ выявляет кластерную структуру данных, разделяет кластеры на \"большие\" и \"малые\" и затем определяет локальность малых кластеров по отношению к большим. Кластеры, чья локальность по отношению к другим мала, определяются как __выбросы__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector = OutlierCBLOF(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Помимо указанных 4 алгоритмов поиска аномалий, можно воспользоваться любым другим, который не встроен в библиотеку, но есть в pyod – например, __histogram-based outlier detection (HBOS)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "hbos = HBOS(contamination=0.1)\n",
    "outlier_detector = OutlierCustom(data_holder, hbos, outlier_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "После выбора алгоритма, его следует применить с помощью метода __apply__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outlier_detector.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты представляют собой список id аномалий (метод __get_outlier_ids__), таблицу с описательными статистиками по аномальным и нормальным объектам (метод __print_result__), а также графическую иллюстрацию важности использованных для поиска аномалий признаков (метод __show_permutation_importance__). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.get_outlier_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.print_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.show_permutation_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OutlierEnsemble`\n",
    "> `OutlierEnsemble` это композиция алгоритмов обнаружения аномалий, итоговой ответ которой представляет собой голосование (объект считается выбросом, если большинство алгоритмов определило его как выброс) следующих алгоритмов: [KNN](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn), [ABOD](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod), [HBOS](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos), [Isolation Forest](https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest). В качестве алгоритмов можно выбрать любое подмножетво из {\"HBOS\", \"ABOD\", \"KNN\", \"IForest\"}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = OutlierEnsemble(data_holder, [\"HBOS\", \"ABOD\", \"KNN\", \"IForest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.print_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## IV. Факторный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Факторный анализ__ – это многомерный метод, применяемый для изучения взаимосвязей между значениями переменных. Предполагается, что известные переменные зависят от меньшего количества неизвестных переменных и случайной ошибки. С помощью факторного анализа возможно выявление скрытых переменных факторов, отвечающих за наличие линейных статистических корреляций между наблюдаемыми переменными.\n",
    "\n",
    "Параметры передаваемые в класс __FactorAnalysis__:\n",
    "- __data_holder (SberPM DataHolder)__ - класс с хранящимися данными\n",
    "- __target_column (str)__ - целевая колонка относительно которой рассчитываются значения $R^2$\n",
    "- __type_of_target (str)__ - Определяет тип целевой колонки. Возможные значения: **number** - числовой, **string** - строковый, **time** - временной.\n",
    "- __categorical_cols (List[str])__ - список столбцов с **категориальными** значениями\n",
    "- __numeric_cols (List[str])__ - список столбцов с **числовыми** значениями\n",
    "- __date_cols (List[str])__ - список столбцов с форматом данных - **время**\n",
    "- __extended_search (Bool)__ - флаг расширенного анализа, т.е. будут применяться дополнительные методы анализа данных. Значение по умолчанию - **False**\n",
    "- __count_others (Bool)__ - расчёт колонки **Прочее**. Значение по умолчанию - **False**\n",
    "\n",
    "Для корректной работы класса необходимо передать название target_column и хотябы один из параметров categorical_cols, numeric_cols или date_cols по которым и будут считаться значения $R^2$.\n",
    "\n",
    "Методы класса **FactorAnalysis**:\n",
    "- __apply()__ - запустит процесс анализа и вернёт результат в виде таблицы (pandas DataFrame)\n",
    "- __get_result()__ - вернёт результат работы факторного анализа, в случае если ранее был запущен метод **apply()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.factor_analysis import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dh = DataHolder('InternationalDeclarations.csv', 'id', 'concept:name', 'time:timestamp')\n",
    "res = FactorAnalysis(data_holder=dh,\n",
    "                     target_column='case:AdjustedAmount',\n",
    "                     type_of_target=\"number\",\n",
    "                     categorical_cols=['org:resource', 'case:Permit ActivityNumber','org:role'],\n",
    "                     numeric_cols=['case:Amount','case:RequestedAmount','case:Permit RequestedBudget'],\n",
    "                     date_cols=['time:timestamp'],\n",
    "                     extended_search=True,\n",
    "                     count_others=True,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Рекомендательная система"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный модуль представляет собой рекомендательную систему, ранжирующую этапы процесса в порядке их приоритетности для реинжениринга. Система показывает, на какие активности нужно обратить внимание в первую очередь при оптимизации процесса. Сначала выбирается лучшая модель, описывающую зависимость таргетной метрики (metric) каждой из Активностей от признаковых метрик (metric_f) всех остальных Активносетй. В качестве метрик могут выступать количество рециклов (количество появлений активности, __\"appearance\"__), время выполнения(__\"time\"__), количество повторений (__\"recycles\"__), кастомная метрика пользователя (\"__user_metric__\"). Далее на основании метрики строятся коэффициенты проблемности, в порядке убывания которых ранжируются Активности.\n",
    "\n",
    "Параметры передаваемые в класс __RecommendSystem__:\n",
    "- __data (SberPM DataHolder)__ - класс с хранящимися данными.\n",
    "- __mode (str = default 'best')__ - настройка качества анализа. Может принимать 2 параметра:\n",
    "    - __'best'__ - провести точный, но долгий расчёт\n",
    "    - __'fast'__ - менее точный, но быстрый рассёт\n",
    "- __metric (str = default 'appearance')__ - целевая метрика ранжирования. Может принимать следующие значения: \n",
    "    - __'appearance'__ - количество появлений Активности;  \n",
    "    - __'time'__ - общее время активности, \n",
    "    - __'recycles'__ - количество рециклов активности;\n",
    "    - __'user_metric'__ - кастомная метрика пользователя.\n",
    "- __metric_f (str = default 'appearance')__ - признаковая метрика, единица измерения независимых Активностей. Может принимать следующие значения: \n",
    "    - __'appearance'__ - количество появлений Активности;  \n",
    "    - __'time'__ - общее время активности, \n",
    "    - __'recycles'__ - количество рециклов активности;\n",
    "    - __'user_metric'__ - кастомная метрика пользователя.\n",
    "    \n",
    "- __user_metric_column__ (str = default None) - название колонки данных, где находится кастомная метрика пользователя.\n",
    "- __user_meric_column_f__ (str = default None) - название колонки данных, где находится признаковая кастомная метрика пользователя.\n",
    "- __auto_i__ (bool = default False) - с учётом уровня проблемности.\n",
    "\n",
    "Методы класса __RecommendSystem__:\n",
    "- __apply()__ - запустит процесс анализа.\n",
    "- __get_result()__ - вернёт pandas DataFrame с указанием кластера каждого текстового поля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.recommendation_system import RecommendSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec_syst = RecommendSystem(data=data_holder, metric='time')\n",
    "Rec_syst.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec_syst.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Рекомендательная система + автоинсайты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rec_syst = RecommendSystem(data=data_holder, metric='time', auto_i=True)\n",
    "Rec_syst.apply()\n",
    "Rec_syst.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный модуль служит для кластеризации текстов. \n",
    "Для каждого кластера алгоритм выдает __номер кластера__ (название кластера или самое близкое сообщение к центроиду кластера), и 10 самых распространенных слов в кластере. Для кластеризации используется отображение текста с помощью нейронной сети word2vec в 300-мерное пространство, дальше используется метод понижения размерности с минимальной потерей информации с помощью алгоритма PCA, полученные данные кластеризуются методом DBSCAN.\n",
    "\n",
    "Параметры передаваемые в класс __TextClustering__:\n",
    "- __data (SberPM DataHolder или pandas DataFrame)__ - класс с хранящимися данными.\n",
    "- __description (str)__ - название колонки, в которой находятся текстовые данные.\n",
    "- __pca_dim (str = default 'medium')__ - режим работы. Может принимать значения 'fast', 'medium', или 'full_quality'.\n",
    "- __type_model_w2v (bool = default True)__ - выбор модели:\n",
    "    - True- общая модель\n",
    "    - Fasle - модель специализированная для сбербанка\n",
    "- __dbscan_eps (float = default 0.5)__ - максимальное расстояние между двумя образцами, чтобы один из них рассматривался как находящийся по соседству с другим.\n",
    "- __min_samples (int = default 2)__ - минимальное количество текстов в кластере, минимальное 2.\n",
    "- __only_unique_descriptions (bool = default False)__ - флаг 'True' оставляет только уникальные записи.\n",
    "- __cluster_marking (List[str] = default None)__ - возможность задать названия нескольких кластеров, к которым будут отнесены максимально близкие записи, а оставшиеся нерелевантные записи также будут кластеризованы.\n",
    "\n",
    "Методы класса __TextClustering__:\n",
    "- __apply()__ - запустит процесс анализа.\n",
    "- __get_result()__ - вернёт pandas DataFrame с указанием кластера каждого текстового поля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.text_clustering import TextClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Clust = TextClustering(data=data_holder, description='some_text', pca_dim='full_quality')\n",
    "Text_Clust.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_Clust.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Сентиментный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный модуль представляет собой систему для анализа тональности словесных комментариев в текстовом поле. Модуль анализа тональности имеет два режима: «базовый» и «продвинутый». В «базовом» режиме тональность текста определяется как «positive» или «negative», численное значение тональности определяется в пределах от -1 до 1 (от негатива к позитиву). Границу двух смежных интервалов можно настроить.\n",
    "\n",
    "В «продвинутом» режиме проводится более точная оценка тональности текста, которая определяется как «positive», «neutral» или «negative»,  численное значение тональности определяется в пределах от -1 до 1 (от негатива к позитиву). Границы трех смежных интервалов  в пределах от -1 до 1, соответствующих пользовательским уровням можно настраивать.\n",
    "\n",
    "Параметры передаваемые в класс __SentimentAnalysis__:\n",
    "- __data (SberPM DataHolder или pandas DataFrame)__ - класс с хранящимися данными.\n",
    "- __text_column (str)__ - название колонки, в которой находятся текстовые данные.\n",
    "- __mode (bool = default False)__ - выбор режима:\n",
    "    - True - «продвинутый», точный режим (для работы необходима модель bert_model)\n",
    "    - Fasle - «базовый» режим работы\n",
    "- __lower_bound (float = default None)__ - нижняя смежная граница двух интервалов. В случае если используется «продвинутый» режим, то задаётся нижняя смежная граница для трёх интервалов.\n",
    "- __upper_bound (float = default None)__ - верхняя смежная граница двух интервалов. Используется в случае использования «продвинутого» режима.\n",
    "\n",
    "\n",
    "Методы класса __SentimentAnalysis__:\n",
    "- __apply()__ - запустит процесс анализа и вернет результат pandas DaraFrame.\n",
    "- __get_result()__ - вернёт результат работы в виде pandas DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.sentimental_analysis import SentimentAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Базовый режим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(data = ['Все плохое 😥', 'Терпимо' , 'Все хорошее', 'Гуд', 'Ужасно🤦‍♀️', 'nice', 'I want pizza',\n",
    "                           '✔', 'Нормально', 'Плохо!! (╯°□°）╯︵ ┻━┻', 'disgusting service'],\n",
    "                   columns = ['text'])\n",
    "Sent_analysis = SentimentAnalysis(data = df, text_column='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_analysis.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Продвинутый режим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_analysis = SentimentAnalysis(data = df, text_column='text', mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_analysis.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Поиск счастливого пути\n",
    "\n",
    "Задачу поиска счастливого пути можно решить с помощью обучения с подкреплением (RL), которое по своей сути адаптировано к поиску оптимальных действий. RL работает с двумя объектами: агентом и средой. Во время обучения агент взаимодействует с окружающей средой, совершает действия и получает обратную связь, которая называется вознаграждением. Задача формулируется в рамках марковского процесса принятия решений, который основан на:\n",
    "* множестве состояний в мире \n",
    "* множестве действий \n",
    "* вероятностном распределении следующего состояния при условии текущего состояния и завершенного действия \n",
    "* награды при переходе между состояниями при выполнении действий. \n",
    "\n",
    "Выполнение марковского свойства состоит в том, что следующее состояние условно не зависит от прошлых состояний и действий, учитывая текущее состояние и действие. Граф процесса рассматривается как среда, состояния — узлы графа (активности), действия — ребра (выбор следующей активности для перехода), награда — среднее отрицательное время перехода между прошлым и настоящим состояниями. При наличии ключевых состояний за переход в них также начисляется награда. Цель состоит в том, чтобы выбрать оптимальную политику — отображение из пространства состояний в пространство действий или, другими словами, руководство к действию в каждом состоянии — которое максимизирует ожидаемую дисконтированную сумму вознаграждений, проходящих через граф процесса.\n",
    "Оптимальная политика и, как следствие, путь находятся при помощи AutoRL с использованием лучшего по дисконтированной сумме наград  метода из:  value iteration,  Q-learning, cross entropy, genetic algorithm.\n",
    "\n",
    "Параметры передаваемые в класс __HappyPath__:\n",
    "- __data_holder (SberPM DataHolder)__ - класс с хранящимися данными\n",
    "- __key_node (str)__ - должен быть один элемент – ключевой узел\n",
    "- __initial_state (str = default \"startevent\")__ - точка старта пути \n",
    "- __reward_for_key (float = default 10.0)__ - награда за ключевой узел\n",
    "- __reward_for_end (float = default 0.0)__ - награда за окончание пути\n",
    "- __prob_increase (float = default 0.5)__ - увеличение вероятности попасть в узел при выборе этого узла с последующей нормировкой\n",
    "- __clear_outliers (float = default 0.05)__ - переходы с вероятностью меньшей, чем эта, не учитываются. Значение должно быть в диапазоне [0,1]\n",
    "- __short_path (int = default None)__ - после какого достижения ключевого узла на пути прекращать давать награду за ключевой узел\n",
    "- __gamma (float = default 1)__ - дисконтирующий фактор\n",
    "- __mode (str = default \"complete\")__ - количество RL алгоритмов для решения задачи. Принимает значения: short, normal, long, complete.\n",
    "- __regime (str = default \"static\")__ - меняется ли среда или нет после очередного достижения ключевого узла. Принимает значения 'dynamic' или 'static'.\n",
    "- __penalty (float = default 0.0)__ - штраф за каждый шаг\n",
    "- __output_algo_params__ (bool = default false) - добавить в вывод параметры выбранного алгоритма \n",
    "- __mut_list_gen (List[float] = default [0.1])__ - вероятность мутации в генетическом алгоритме\n",
    "- __children_list_gen (List[int] = default [100])__ - численность популяции в генетическом алгоритме\n",
    "- __iters_list_gen (List[int] = default [400])__ - количество популяций в генетическом алгоритме\n",
    "- __percentile_list_cem (List[int] = default [20])__ - квантиль элитных сессий в алгоритме кросс энтропии\n",
    "- __learning_list_cem (List[float] = default [0.1])__ - скорость обучения в алгоритме кросс энтропии\n",
    "- __iters_list_cem (List[int] = default [800])__ - количество итераций в алгоритме кросс энтропии\n",
    "- __alpha_list (List[float] = default [0.15])__ - скорость обучения в алгоритме Q-learning\n",
    "- __epsilon_list_q (List[float] = default [0.1])__ - вероятность epsilon-greedy policy в алгоритме Q-learning\n",
    "- __iters_list_q (List[int] = default [4000])__ -количество итераций в алгоритме Q-learning\n",
    "- __iters_list_vi (List[int] = default [50])__ - количество итераций в алгоритме value iteration\n",
    "- __num_iter_list_vi (List[int] = default [250])__ - максимум повторений до сходимости в алгоритме value iteration\n",
    "\n",
    "\n",
    "Методы класса __HappyPath__:\n",
    "- __apply()__ - запустит процесс анализа\n",
    "- __get_df_rl()__ - вернёт результат с указанием лучшего пути, количеством награды (rewards), и успешность прохождения в виде таблицы DataFrame.\n",
    "- __get_best_algo()__ - вернёт имя лучшего алгоритма\n",
    "- __get_best_path()__ - вернёт счастливый путь\n",
    "- __get_best_rew()__ - вернёт количество наград лучшего алгоритма\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.happy_path import HappyPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfna = pd.read_csv('log_happy_path.csv',\n",
    "                   encoding = 'windows-1251', sep = ';')\n",
    "dh_for_HP = DataHolder(dfna, id_column = 'ID_PRODUCT', activity_column = 'EVENT_NAME', \n",
    "                          start_timestamp_column = 'EVENT_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = HappyPath(dh_for_HP, key_node = 'Печать договора', output_algo_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.get_df_rl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.get_best_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.get_best_rew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.get_best_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация HappyPath на графе\n",
    "\n",
    "Для визуализации следует воспользоваться методом **apply_happy_path** классов `sberpm.visual.GraphvizPainter`. \n",
    "Нужно подать :\n",
    "- **граф** для отрисовки (на нём может быть меньше нод/рёбер, чем в таблицах автоинсайтов), \n",
    "- **объект `HappyPath`**, у которого был вызван метод apply\n",
    "- __hide_disconnected_nodes (bool = default False)__ - флаг отрисовки изолированных узлов (узлов без входных и выходных переходов). Если False, то такие узлы отображаться не будут.\n",
    "- __edges_widths (float = default 3.0)__ - толщина стрелок перехода HappyPath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleminer = SimpleMiner(dh_for_HP)\n",
    "simpleminer.apply()\n",
    "graph = simpleminer.graph\n",
    "\n",
    "# Создание объекта GraphvizPainter\n",
    "painter = GraphvizPainter()\n",
    "\n",
    "# Применение HappyPath\n",
    "painter.apply_happy_path(graph, HP)\n",
    "\n",
    "# Можно вывыести граф в notebook\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Предсказание структуры графа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс __GSPredictor__ (graph structure predictor) содержит алгоритм предсказания структуры графа, а именно, предсказываются две величины: вероятности и средние времена выполнения нод и рёбер графа. Эти величины представляются как временные ряды, получаемые из имеющихся данных, далее используются ml- и специализированные для работы с временными рядами алгоритмы для предсказания.\n",
    "\n",
    "Шаги алгоритма:\n",
    "\n",
    "    I. Подготовка данных\n",
    "\n",
    "    1. Расчёт временных рядов для нод и рёбер\n",
    "        a) вероятности нод/рёбер\n",
    "           (сумма вероятностей нод/рёбер в одном временном промежутке равна 1;\n",
    "            или 0 если в данном временном промежутке не было ни одной ноды/ни одного ребра)\n",
    "        b) средние времена выполнения нод/рёбер\n",
    "\n",
    "    2. Превращение врем. рядов в матрицы лагов и добавление дополнительной информации:\n",
    "        - разница лаг-колонок\n",
    "        - one-hot encoding месяцев (если одна точка временного ряда представляет собой месяц или год)\n",
    "        - число рабочих дней в месяце (если одна точка временного ряда представляет собой месяц)\n",
    "\n",
    "    II. Предсказание (следующие шаги выполняются для каждого врем. ряда/матрицы лагов)\n",
    "\n",
    "    0. Данные разделяются на 3 части: \"train\", \"test\", \"val\".\n",
    "    1. Используется перебор параметров для поиска лучшей ml-модели на \n",
    "       train/test данных.\n",
    "    2. Используются несколько алгоритмов отборов признаков для поиска лучших признаков на train/test данных. Здесь используется        ml-модель, найденная на предыдущем шаге.\n",
    "    3. Выполняется шаг 1 (поиск лучшей модели) с некоторыми отличиями:\n",
    "        a) используется больше моделей: те же ml-модели + Sarimax и Holt\n",
    "        b) другие данные используются для обучения/тестирования: train+test/val\n",
    "        c) используются только \"лучшие признаки\" данных, найденные на предыдущем шаге\n",
    "    4. Признаки из шага 2 (и 3) и модель из шага 3 используются для предсказания результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Параметры__\n",
    "​\n",
    "- __data_holder__: DataHolder\n",
    "​\n",
    "- __test_size: float, default=0.1__<br>&nbsp;\n",
    "    Размер \"тест\" части, даля от общего объёма данных.\n",
    "​\n",
    "- __val_size: float, default=0.1__<br>&nbsp;\n",
    "    Размер \"val\" части, даля от общего объёма данных.\n",
    "​\n",
    "- __pred_period: int, default=5__<br>&nbsp;\n",
    "    Кол-во точек временного ряда, которые нужно предсказать.\n",
    "​\n",
    "- __period_type: {'D', 'M', 'Y'}__<br>&nbsp;\n",
    "    Временной промежуток одной точки временного ряда (гранулярность): день, месяц, год.\n",
    "​\n",
    "- __two_models: bool, default=False__<br>&nbsp;\n",
    "    Если True, также перебрать все возможные комбинации из двух ml-моделей и объеденить их результат.\n",
    "​\n",
    "- __edges: bool, default=False__<br>&nbsp;\n",
    "    Если False, делать предсказания только для нод.\n",
    "    Если True, для нод и рёбер.\n",
    "​\n",
    "- __refit: bool, default=False__<br>&nbsp;\n",
    "    Если True, переобучать модель на каждом шаге при финальном предсказании,\n",
    "    используя имеющиеся данние и те, которые уже предсказаны.\n",
    "​\n",
    "- __quick_mod: bool, default=False__ <br>&nbsp;\n",
    "    быстрый режим прогноза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Методы__ (для отображения результата)\n",
    "\n",
    "nodes/edges - ноды/рёбра<br>\n",
    "prob/duration - вероятность/среднее время выполнения\n",
    "\n",
    "- plot_nodes_prob()\n",
    "- plot_nodes_duration()\n",
    "- plot_edges_prob()\n",
    "- plot_edges_duration()\n",
    "\n",
    "\n",
    "\n",
    "- __get_predicted_graph()__ - отрисует спрогнозированный SimpleMiner граф из последнего прогноза только с узлами, которые имеют вероятность больше, чем base_probability.\n",
    "    - __base_probability__ - пороговое значение вероятности узла. Если если значение вероятности будет меньше заданного, то узел не будет отрисован."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Аттрибуты__\n",
    "\n",
    "после работы алгорима временные ряды содержатся внутри класса\n",
    "\n",
    "pred - предсказанные временные ряды<br>\n",
    "без pred - врем. ряды, построенные на имеющихся данных\n",
    "\n",
    "- nodes_prob: pd.DataFrame\n",
    "- nodes_duration: pd.DataFrame\n",
    "- edges_prob: pd.DataFrame\n",
    "- edges_duration: pd.DataFrame\n",
    "\n",
    "- nodes_prob_pred: pd.DataFrame\n",
    "- nodes_duration_pred: pd.DataFrame\n",
    "- edges_prob_pred: pd.DataFrame\n",
    "- edges_duration_pred: pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.graph_structure_prediction import GSPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_time_series.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHolder(df, 'id', 'act', 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# предсказание только для нод на 4 дня вперёд\n",
    "\n",
    "gsp = GSPredictor(dh, period_type='D', pred_period=4, two_models=False, edges=False, quick_mod = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.plot_nodes_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.plot_nodes_duration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Спрогнозированные вероятности нод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.nodes_prob_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Спрогнозированные длительности нод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.nodes_duration_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gsp.get_predicted_graph()\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## X. Имитационное моделирование и what-if анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль имитационного моделирования __`sberpm.imitation`__ позволяет симулировать процесс в as-is форме, вносить изменения в процесс и проводить what-if моделирование, а также оценивать качество симуляции по сравнению с исходным лог-файлом с помощью классов `Simulation` и `SimilarityMetric` соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.imitation import Simulation, SimilarityMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы класса `Simulation`:\n",
    "- __run__ – запуск симуляции num_traces (количество) цепочек активностей (id)\n",
    "- __to_initial_state__ – возврат процесса к изначальному состоянию\n",
    "- __mean_duration__ – средняя длительность выполнения активностей или переходов в процессе\n",
    "- __change_node_duration__ и __change_edge_duration__ – ограничение времени выполнения конкретной активности или перехода\n",
    "- __delete_node__ и __delete_edge__ – удаление ноды (активности) и ребра (перехода) из процесса соответственно\n",
    "- __get_nodes_insights__ и __get_edges_insights__ – поиск инсайтов по нодам и ребрам процесса соответственно\n",
    "- __delete_nodes_insights__ и __delete_edges_insights__ – удаление инсайтов, обнаруженных по нодам и ребрам процесса соответственно \n",
    "\n",
    "На вход класс принимает обьект типа DataHolder. Можно также зафиксировать __random_state__, чтобы результаты были воспроизводимыми. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Инициализация\n",
    "sim = Simulation(data_holder) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As-is моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Метод __run__ запускает симуляцию процесса. Он имеет параметры __num_traces__ – число цепочек событий для симуляции и __max_trace_length__ – максимальная длина сгенерированной цепочки (по умолчанию 100). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Симуляция исходного числа цепочек (id)\n",
    "sim_data = sim.run(num_of_traces=len(data_holder.grouped_data))\n",
    "sim_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный лог можно отрисовать с помощью майнера и встроенного инструмента для визуализации графов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataHodler для сгенерированных данных\n",
    "holder_sim = DataHolder(sim_data, 'id', 'stages', 'dt')\n",
    "\n",
    "# Майнер\n",
    "miner = HeuMiner(holder_sim)\n",
    "miner.apply()\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(miner.graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество симуляции можно проверить с помощью класса `SimilarityMetric`, который измеряет сходство исходного и сгенерированного лога с помощью _расстояния Дамерау-Левенштейна_. На вход класс принимает лог, полученный в ходе симуляции, и DataHolder исходного файла. Результат хранится в поле __similarity__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sim_metric = SimilarityMetric(sim_data, data_holder)\n",
    "print('Сходство:', sim_metric.similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также посмотреть метрику сходства для каждой цепочки из сгенерированного лога отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_metric.result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество симуляции невысокое из-за особенностей синтетического датасета. На реальном лог-файле качество значительно выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What-if анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Методы __delete_node__ и __delete_edge__ позволяют удалить активность или ребро в процессе. После запуска симуляции процесс будет реализовываться по альтернативным путям. Параметры __node__ и __edge__ – названия активности и перехода в процессе соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sim.delete_node('Stage_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Симуляция процесса без ноды \n",
    "sim_data = sim.run(num_of_traces=len(data_holder.grouped_data))\n",
    "\n",
    "# Создание DataHolder\n",
    "holder_sim = DataHolder(sim_data, 'id', 'stages', 'dt')\n",
    "\n",
    "# Майнер\n",
    "miner = HeuMiner(holder_sim)\n",
    "miner.apply()\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(miner.graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для возврата процесса к исходному состоянию необходимо воспользоваться методом __to_initial_state__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.to_initial_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода __mean_duration__ можно проанализировать среднюю продолжительность выполнения всех активностей или переходов в процессе (зависит от параметра  __mode__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.mean_duration(target='activities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Методы __change_activity_duration__ и __change_transition_duration__ позволяют ограничить время выполнения конкретной активности или перехода. Они имеют следующие параметры:\n",
    "- __activity__ или __transition__ – название активности или перехода для ограничения\n",
    "- __threshold__ – максимальная продолжительность выполнения активности или перехода\n",
    "- __scale__ – коэффициент уменьшения (если > 1) или увеличения (если < 1) продолжительности выполнения активности или перехода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.change_activity_duration(activity='Stage_0', scale=3)  # уменьшить в 3 раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Симуляция с уменьшенной длительностью ноды\n",
    "sim_data = sim.run(num_of_traces=len(data_holder.grouped_data))\n",
    "\n",
    "# Создание DataHolder\n",
    "holder_sim = DataHolder(sim_data, 'id', 'stages', 'dt')\n",
    "\n",
    "# Расчет метрик для добавления на граф\n",
    "time_metric = ActivityMetric(holder_sim, time_unit='s')\n",
    "mean_time_node_metric = time_metric.mean_duration().fillna(0).to_dict()\n",
    "\n",
    "# Майнер\n",
    "miner = HeuMiner(holder_sim)\n",
    "miner.apply()\n",
    "graph = miner.graph\n",
    "graph.add_node_metric('mean_time', mean_time_node_metric)\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(miner.graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.mean_duration('activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возврат к изначальному состоянию\n",
    "sim.to_initial_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках what-if анализа можно также произвести поиск инсайтов с помощью метода __get_insights__, основанных на модуле автоматического поиска инсайтов, и удалить их с помощью __delete_activities_insights__ и __delete_transitions_insights__ соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_insights(mode='activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.delete_activities_insights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Симуляция процесса без инсайтов \n",
    "sim_data = sim.run(num_of_traces=len(data_holder.grouped_data))\n",
    "\n",
    "# Создание DataHolder\n",
    "holder_sim = DataHolder(sim_data, 'id', 'stages', 'dt')\n",
    "\n",
    "# Майнер\n",
    "miner = HeuMiner(holder_sim)\n",
    "miner.apply()\n",
    "\n",
    "# Отрисовка\n",
    "painter = GraphvizPainter()\n",
    "painter.apply(miner.graph)\n",
    "painter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XI. Decision Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль __`sberpm.decision_mining`__ предназначен для проведения __decision point analysis__, который заключается в определении причин, почему процесс идет по тому или иному пути. Класс `DecisionMining` выявляет, как те или иные свойства (атрибуты) процесса влияют на выбор конкретного пути. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.decision_mining import DecisionMining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На вход `DecisionMining` принимает объект типа DataHolder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация\n",
    "dm = DecisionMining(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DecisionMining` имеет следующие методы:\n",
    "- __print_decision_points__ – выводит decision points (активности, после которых идет выбор)\n",
    "- __apply__ – выполняет анализ decision points, строя дерево решений по указанным атрибутам\n",
    "- __get_clf_metrics__ – выводит метрики классификации\n",
    "- __plot_confusion_matrix__ – рисует матрицы ошибок\n",
    "- __plot_feature_importance__ – рисует важность признаков в дереве\n",
    "- __plot_feature_distribution__ – рисует распределение признаков по классам \n",
    "- __plot_decision_tree__ – рисует дерево решений\n",
    "- __print_decision_rule__ – выводит решающие правила"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision points – точки, где процесс имеет разветвление, можно посмотреть с помощью метода __print_decision_points__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.print_decision_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод __apply__ запускает алгоритм decision mining. Он имеет следующие параметры:\n",
    "- __categorical_attrs__ – названия категориальных признаков\n",
    "- __noncategorical_attrs__ – названия некатегориальных признаков\n",
    "- __decision_points__ – точки, по которым необходимо построить деревья решений, по умолчанию рассматриваются все\n",
    "- __sampling__ – нужен ли sampling (over- или under-), следует использовать в случае несбалансированных классов\n",
    "- __tree_params__ – параметры дерева решений\n",
    "- __grid_search__ – нужен ли подбор оптимальных гиперпараметров дерева решений\n",
    "- __param_grid__ – сетка параметров, используется только при grid_search=True\n",
    "- __random_state__ – используется в дереве решений и sampling\n",
    "- __n_jobs__ – используется в sampling и grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.apply(categorical_attrs=[data_holder.user_column],\n",
    "         noncategorical_attrs=[data_holder.duration_column],\n",
    "         decision_points='all', \n",
    "         sampling='RandomOverSampler',\n",
    "         tree_params='default',\n",
    "         grid_search=False, \n",
    "         param_grid='default',\n",
    "         random_state=42,\n",
    "         n_jobs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты классификации можно посмотреть с помощью методов __get_clf_metrics__, __plot_confusion_matrix__ и __plot_feature_importance__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.get_clf_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество невысокое из-за особенностей синтетического датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все plot методы имеют параметры:\n",
    "- __decision_points__ – точки, для которых необходимо изобразить харатеристики\n",
    "- __savefig__ – нужно ли сохранить изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_confusion_matrix(decision_points=['Stage_0'], savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_feature_importance(decision_points=['Stage_0'], savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод __plot_feature_importance__ дополнительно имеет еще два параметра:\n",
    "- __drop_outliers__ – нужно ли удалить выбросы для количественных признаков\n",
    "- __clf_results__ – нарисовать распределение признаков по результатам классификации (True) или по исходному логу (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_feature_distribution(decision_points=['Stage_0'], drop_outliers=True, clf_results=True, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы __plot_decision_tree__ и __print_decision_rule__ выводят результаты работы decision mining алгоритма в виде дерева и правил соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры __plot_decision_tree__:\n",
    "- __decision_points__ – точки, для которых необходимо нарисовать дерево решений\n",
    "- __max_depth__ – максимальная глубина дерева\n",
    "- __scale__ – масштаб графика\n",
    "- __savefig__ – нужно ли сохранить изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_decision_tree(decision_points=['Stage_0'], max_depth=None, scale=1, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры __print_decision_rule__:\n",
    "- __decision_points__ – точки, для которых необходимо вывести решающие правила\n",
    "- __paths__ – пути, по которым необходимо вывести решающие правила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.print_decision_rule(decision_points=['Stage_0'], paths=['Stage_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XII. Хронометраж"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт длительности процесса с предварительной очисткой вывбросов при помоощи алгоритмов машинного обучения.\n",
    "\n",
    "- __data_holder (SberPM DataHolder)__ - класс с хранящимися данными \n",
    "- __start_query__ (str) - запрос указывающий на начало нового процесса\n",
    "- __end_query__ (str) - запрос указывающий на окончание процесса\n",
    "- __query__ (str) - запрос указывающий на начало нового процесса или на завершение процесса в данной строке\n",
    "- __change_columns__ (List[str]) - список с названиями колонок по которым можно определить что начался новый процесс при изменении значения в колонке (например изменения идентификатора процесса или пользователя) \n",
    "- __sort_params__ (List[str]) - список названий колонок по которым будет производиться предварительная сортировка данных\n",
    "\n",
    "Параметры __query__, __start_query__, __end_query__ могут быть типа __\"sql\"__ или __\"pandas\"__, они оба должны ссылаться на фрейм данных как __\"df\"__, они должны возвращать один столбец: булевую маску или столбец из 0 и 1.\n",
    "\n",
    "В случае, если задаётся __\"sql\"__ запрос, то он должен выглядеть как __\"SELECT ... from df\"__.\n",
    "\n",
    "Метод __get_chrono()__ начнёт процесс расчёта длительности процесса и в результате выведет словарь(dict) с элементами:\n",
    "- среднее временя процесса в секундах\n",
    "- количество отобранных элементов\n",
    "- количество уникальных процессов\n",
    "- максимальное количество уникальных идентификаторов рассчитанных в хронометраже \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sberpm.ml.chronometrage import Chronometrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('chrono_data.xlsx', engine='openpyxl')\n",
    "dh = DataHolder(df, 'process_id', 'event_type', 'data_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_start_query = \"\"\"(df['event_type'] == 'Процесс_16961') & (df['event_action'].isin(['Начало']))\"\"\"\n",
    "example_end_query = \"\"\"(df['event_type'] == 'Процесс_16961') & (df['event_action'].isin(['Конец']))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = Chronometrage(dh, \n",
    "                   sort_params=['process_id', 'user_id', 'data_timestamp'], \n",
    "                   start_query=example_start_query,\n",
    "                   end_query=example_end_query,\n",
    "                   change_columns=['process_id', 'user_id'])\n",
    "res = cr.get_chrono()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.pm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "a5b3d609ea34d905782f74e70b860c8b5093bfe8c4c29182a72689cb5f1bcef4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
